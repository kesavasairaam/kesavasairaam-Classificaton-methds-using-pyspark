{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification methods using Pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zWMbBsvRqxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341c42e3-4998-4096-cc50-09c8b84ea5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 30 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 63.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=f65e193f2299886eb8d2e2b888537288fde074aab25514aef5d880909dcb0cf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UqfwyGzwTJ2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50555b4f-040c-4591-b541-2d17afb6010e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binomial logistic regression"
      ],
      "metadata": {
        "id": "rOvBRzE6SAAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName('Logistic Regression').getOrCreate()"
      ],
      "metadata": {
        "id": "2BNsdpvoTnfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n"
      ],
      "metadata": {
        "id": "OFIBUzDBRzX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load training data\n",
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")\n"
      ],
      "metadata": {
        "id": "FThF7MXRSLWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = LogisticRegression(maxIter=10, \n",
        "                        regParam=0.3, \n",
        "                        elasticNetParam=0.8)\n"
      ],
      "metadata": {
        "id": "Ubj-LwtPSMMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(df)\n"
      ],
      "metadata": {
        "id": "t_sc3zYSSKPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the coefficients and intercept for logistic regression\n",
        "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
        "print(\"Intercept: \" + str(lrModel.intercept))\n"
      ],
      "metadata": {
        "id": "HhJL6Q1lSJig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9565fdf9-b1f4-4a42-cbb9-d8962b6d3d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: (692,[272,300,323,350,351,378,379,405,406,407,428,433,434,435,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.52068987138421e-05,-8.115773146847101e-05,3.814692771846369e-05,0.0003776490540424337,0.00034051483661944103,0.0005514455157343105,0.0004085386116096913,0.000419746733274946,0.0008119171358670028,0.0005027708372668751,-2.3929260406601844e-05,0.000574504802090229,0.0009037546426803721,7.818229700244018e-05,-2.1787551952912764e-05,-3.4021658217896256e-05,0.0004966517360637634,0.0008190557828370367,-8.017982139522704e-05,-2.7431694037836214e-05,0.0004810832226238988,0.00048408017626778765,-8.926472920011488e-06,-0.00034148812330427335,-8.950592574121486e-05,0.00048645469116892167,-8.478698005186209e-05,-0.0004234783215831763,-7.29653577763134e-05])\n",
            "Intercept: -0.5991460286401435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We can also use the multinomial family for binary classification\n",
        "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n"
      ],
      "metadata": {
        "id": "zqiH9L2SSIoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "mlrModel = mlr.fit(df)\n"
      ],
      "metadata": {
        "id": "N0bIai8LSH2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
        "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
        "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
      ],
      "metadata": {
        "id": "YxavzdvCSG7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
        "# in the earlier example\n",
        "trainingSummary = lrModel.summary\n"
      ],
      "metadata": {
        "id": "FglRbbIHURXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtain the objective per iteration\n",
        "objectiveHistory = trainingSummary.objectiveHistory\n",
        "print(\"objectiveHistory:\")\n",
        "for objective in objectiveHistory:\n",
        "    print(objective)\n"
      ],
      "metadata": {
        "id": "BHOYn_RAUU_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
        "trainingSummary.roc.show()\n",
        "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n"
      ],
      "metadata": {
        "id": "KXILFo0CUUEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the model threshold to maximize F-Measure\n",
        "fMeasure = trainingSummary.fMeasureByThreshold\n",
        "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
        "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
        "    .select('threshold').head()['threshold']\n",
        "lr.setThreshold(bestThreshold)"
      ],
      "metadata": {
        "id": "5RWF3Pp8UTIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Logistics Regression"
      ],
      "metadata": {
        "id": "usdt7xOGUEfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Load training data\n",
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_multiclass_classification_data.txt\")\n",
        "############################################\n",
        "# Load training data\n",
        "#training = spark \\\n",
        "#    .read \\\n",
        "#    .format(\"libsvm\") \\\n",
        "#    .load(\"data/mllib/sample_multiclass_classification_data.txt\")\n",
        "#################################"
      ],
      "metadata": {
        "id": "rxDoGMszUuu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n"
      ],
      "metadata": {
        "id": "uTerrk2kVGeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(df)\n"
      ],
      "metadata": {
        "id": "oQ4RmkPYVQyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the coefficients and intercept for multinomial logistic regression\n",
        "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
        "print(\"Intercept: \" + str(lrModel.interceptVector))\n"
      ],
      "metadata": {
        "id": "glYAVXCjVP81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainingSummary = lrModel.summary\n"
      ],
      "metadata": {
        "id": "g_rTNAMSVPSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtain the objective per iteration\n",
        "objectiveHistory = trainingSummary.objectiveHistory\n",
        "print(\"objectiveHistory:\")\n",
        "for objective in objectiveHistory:\n",
        "    print(objective)\n"
      ],
      "metadata": {
        "id": "exk9H_A1VOUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for multiclass, we can inspect metrics on a per-label basis\n",
        "print(\"False positive rate by label:\")\n",
        "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
        "    print(\"label %d: %s\" % (i, rate))\n"
      ],
      "metadata": {
        "id": "MDAUueTNVNaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"True positive rate by label:\")\n",
        "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
        "    print(\"label %d: %s\" % (i, rate))\n"
      ],
      "metadata": {
        "id": "3sIIhE5xVMnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Precision by label:\")\n",
        "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
        "    print(\"label %d: %s\" % (i, prec))\n"
      ],
      "metadata": {
        "id": "87JWsjh1VL3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Recall by label:\")\n",
        "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
        "    print(\"label %d: %s\" % (i, rec))\n"
      ],
      "metadata": {
        "id": "qiT6HW0kVLFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"F-measure by label:\")\n",
        "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
        "    print(\"label %d: %s\" % (i, f))\n"
      ],
      "metadata": {
        "id": "PqcD4xQuVKK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy = trainingSummary.accuracy\n",
        "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
        "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
        "fMeasure = trainingSummary.weightedFMeasure()\n",
        "precision = trainingSummary.weightedPrecision\n",
        "recall = trainingSummary.weightedRecall"
      ],
      "metadata": {
        "id": "qBn4_WEXVJN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
        "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
      ],
      "metadata": {
        "id": "KZEhNlfaVIIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree classifier"
      ],
      "metadata": {
        "id": "efGqH-n3Vy9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "Br5eHdSNV2Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data stored in LIBSVM format as a DataFrame.\n",
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")\n"
      ],
      "metadata": {
        "id": "mZcPKin8WKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", \n",
        "                             outputCol=\"indexedLabel\").fit(df)\n",
        "# Automatically identify categorical features, and index them.\n",
        "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", \n",
        "                  outputCol=\"indexedFeatures\",\n",
        "                  maxCategories=4).fit(df)\n"
      ],
      "metadata": {
        "id": "lXYaJC77WHyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n"
      ],
      "metadata": {
        "id": "CkJ-LKmrWGxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train a DecisionTree model.\n",
        "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", \n",
        "                            featuresCol=\"indexedFeatures\")\n"
      ],
      "metadata": {
        "id": "BUFLkEhkWFv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chain indexers and tree in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, \n",
        "                            featureIndexer, \n",
        "                            dt])\n"
      ],
      "metadata": {
        "id": "4MmjJ7b-WFES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n"
      ],
      "metadata": {
        "id": "EVs0gyZ4WEKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n"
      ],
      "metadata": {
        "id": "3WAu83TWWDNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \n",
        "                   \"indexedLabel\", \n",
        "                   \"features\").show(5)\n"
      ],
      "metadata": {
        "id": "sJr4YjqaWB--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b717f31-8c86-47c7-f07f-d4ab4813252a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+--------------------+\n",
            "|prediction|indexedLabel|            features|\n",
            "+----------+------------+--------------------+\n",
            "|       1.0|         1.0|(692,[98,99,100,1...|\n",
            "|       1.0|         1.0|(692,[123,124,125...|\n",
            "|       1.0|         1.0|(692,[124,125,126...|\n",
            "|       1.0|         1.0|(692,[124,125,126...|\n",
            "|       1.0|         1.0|(692,[124,125,126...|\n",
            "+----------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", \n",
        "    predictionCol=\"prediction\", \n",
        "    metricName=\"accuracy\")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n"
      ],
      "metadata": {
        "id": "SaEFXr7nV-2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQsErdYaDuRx",
        "outputId": "025a6d9c-552e-40a7-ab62-9b6684c7d8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Error = %g \" % (1.0 - accuracy))\n"
      ],
      "metadata": {
        "id": "AS9251F_WAOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c806e34-efe1-49bd-bcd2-9ee6a9911db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "treeModel = model.stages[2]\n",
        "# summary only\n",
        "print(treeModel)"
      ],
      "metadata": {
        "id": "vzBKe94fV93P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9ae3b2-2ae9-4f6c-db0e-e603530a63f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_f463ca5eff8e, depth=2, numNodes=5, numClasses=2, numFeatures=692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest classifier"
      ],
      "metadata": {
        "id": "HviZAk3pWr8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "uGEFYFNDWsoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and parse the data file, converting it to a DataFrame.\n",
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")\n"
      ],
      "metadata": {
        "id": "2YgpmkUcWzxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", \n",
        "                             outputCol=\"indexedLabel\").fit(df)\n"
      ],
      "metadata": {
        "id": "dih_5hzxW-qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", \n",
        "                  outputCol=\"indexedFeatures\", \n",
        "                  maxCategories=4).fit(df)\n"
      ],
      "metadata": {
        "id": "6u-P34uOW90i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n"
      ],
      "metadata": {
        "id": "GBg69UbcW82K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", \n",
        "                            featuresCol=\"indexedFeatures\",\n",
        "                            numTrees=10)\n"
      ],
      "metadata": {
        "id": "Y1CcUm-mW63B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", \n",
        "                               outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n"
      ],
      "metadata": {
        "id": "heB9x1dnW53q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, \n",
        "                            featureIndexer, \n",
        "                            rf, \n",
        "                            labelConverter])\n"
      ],
      "metadata": {
        "id": "ozRu5gpVW44Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n"
      ],
      "metadata": {
        "id": "LaTsBb-gW4JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n"
      ],
      "metadata": {
        "id": "UDL-UDDnW3VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"predictedLabel\", \n",
        "                   \"label\", \n",
        "                   \"features\").show(5)\n"
      ],
      "metadata": {
        "id": "CWOcrNbEW2pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22a4616-4518-4ed0-b765-c2fb6678bbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+--------------------+\n",
            "|predictedLabel|label|            features|\n",
            "+--------------+-----+--------------------+\n",
            "|           0.0|  0.0|(692,[95,96,97,12...|\n",
            "|           0.0|  0.0|(692,[100,101,102...|\n",
            "|           0.0|  0.0|(692,[122,123,148...|\n",
            "|           0.0|  0.0|(692,[124,125,126...|\n",
            "|           0.0|  0.0|(692,[128,129,130...|\n",
            "+--------------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", \n",
        "    predictionCol=\"prediction\", \n",
        "    metricName=\"accuracy\")\n",
        "\n",
        "print(accuracy)\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
      ],
      "metadata": {
        "id": "DRSdubLCW1sD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65fcb9c0-18e1-4450-9195-f361f8608102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Test Error = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfModel = model.stages[2]\n",
        "print(rfModel)  # summary only"
      ],
      "metadata": {
        "id": "jm3QTvEyW04j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ab776d-9b52-40de-fcbd-78fe49720581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassificationModel: uid=RandomForestClassifier_8be74521cd7b, numTrees=10, numClasses=2, numFeatures=692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient-boosted tree classifier"
      ],
      "metadata": {
        "id": "6jccuuC8XVsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "03tfMLcKXWZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and parse the data file, converting it to a DataFrame.\n",
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")\n"
      ],
      "metadata": {
        "id": "oDrL9Z8ZXief"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df)\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df)\n"
      ],
      "metadata": {
        "id": "vSa-K2FQXhm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n"
      ],
      "metadata": {
        "id": "7IzKaNssXgqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n"
      ],
      "metadata": {
        "id": "DPoZmEWxXf2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chain indexers and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n"
      ],
      "metadata": {
        "id": "AYOJ30a4XfAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n"
      ],
      "metadata": {
        "id": "hlZl-z50XeNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n"
      ],
      "metadata": {
        "id": "5ibwSpl6Xdbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n"
      ],
      "metadata": {
        "id": "PIg2s4vVXcxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
      ],
      "metadata": {
        "id": "2LFBOTxdXb6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only"
      ],
      "metadata": {
        "id": "rfWcZhFuXaz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilayer perceptron classifier"
      ],
      "metadata": {
        "id": "6FJj9BCYX46z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "NxOiSbvPX5hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load training data\n",
        "df = spark.read.format(\"libsvm\")\\\n",
        "    .load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_multiclass_classification_data.txt\")\n"
      ],
      "metadata": {
        "id": "nQyjLk-DYD5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into train and test\n",
        "splits = df.randomSplit([0.6, 0.4], 1234)\n",
        "train = splits[0]\n",
        "test = splits[1]\n"
      ],
      "metadata": {
        "id": "tgGr-4RaYC97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# specify layers for the neural network:\n",
        "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
        "# and output of size 3 (classes)\n",
        "layers = [4, 5, 4, 3]\n"
      ],
      "metadata": {
        "id": "MUclOsPvYCJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n"
      ],
      "metadata": {
        "id": "NGtzov9UYBcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train the model\n",
        "model = trainer.fit(train)\n"
      ],
      "metadata": {
        "id": "PCH0FbaVX-sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# compute accuracy on the test set\n",
        "result = model.transform(test)\n",
        "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n"
      ],
      "metadata": {
        "id": "TqcEJXZPX96q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "metadata": {
        "id": "tc5DUq86X_8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Support Vector Machine Classifier"
      ],
      "metadata": {
        "id": "Rw-qq3hSYvp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n"
      ],
      "metadata": {
        "id": "cx-bs9CeY0gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load training data\n",
        "training = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")\n"
      ],
      "metadata": {
        "id": "HuZQtN5-Y6_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n"
      ],
      "metadata": {
        "id": "xTXqFyesY6Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "lsvcModel = lsvc.fit(training)\n"
      ],
      "metadata": {
        "id": "O9ua3biWY49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the coefficients and intercept for linear SVC\n",
        "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
        "print(\"Intercept: \" + str(lsvcModel.intercept))"
      ],
      "metadata": {
        "id": "XH7_XoXQY4Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "nraohrHYZMOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "zTWl2nZQZM5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load training data\n",
        "data = spark.read.format(\"libsvm\") \\\n",
        "    .load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")\n"
      ],
      "metadata": {
        "id": "Tw1EtqIxZXbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into train and test\n",
        "splits = data.randomSplit([0.6, 0.4], 1234)\n",
        "train = splits[0]\n",
        "test = splits[1]\n"
      ],
      "metadata": {
        "id": "HTc7rpH2ZWog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create the trainer and set its parameters\n",
        "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n"
      ],
      "metadata": {
        "id": "iiTRthg9ZV1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train the model\n",
        "model = nb.fit(train)\n"
      ],
      "metadata": {
        "id": "OiMkxZfCZVDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# select example rows to display.\n",
        "predictions = model.transform(test)\n",
        "predictions.show()\n"
      ],
      "metadata": {
        "id": "SKLIV8YCZUNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# compute accuracy on the test set\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                              metricName=\"accuracy\")\n"
      ],
      "metadata": {
        "id": "mXZ13zqCZSIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "id": "si2hQuG0ZTXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Test set accuracy = \" + str(accuracy))"
      ],
      "metadata": {
        "id": "0NX-FbGuZRRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}